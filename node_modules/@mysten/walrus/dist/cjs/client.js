"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __typeError = (msg) => {
  throw TypeError(msg);
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __accessCheck = (obj, member, msg) => member.has(obj) || __typeError("Cannot " + msg);
var __privateGet = (obj, member, getter) => (__accessCheck(obj, member, "read from private field"), getter ? getter.call(obj) : member.get(obj));
var __privateAdd = (obj, member, value) => member.has(obj) ? __typeError("Cannot add the same private member more than once") : member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
var __privateSet = (obj, member, value, setter) => (__accessCheck(obj, member, "write to private field"), setter ? setter.call(obj, value) : member.set(obj, value), value);
var __privateMethod = (obj, member, method) => (__accessCheck(obj, member, "access private method"), method);
var client_exports = {};
__export(client_exports, {
  WalrusClient: () => WalrusClient,
  walrus: () => walrus
});
module.exports = __toCommonJS(client_exports);
var import_bcs = require("@mysten/bcs");
var import_client = require("@mysten/sui/client");
var import_transactions = require("@mysten/sui/transactions");
var import_utils = require("@mysten/sui/utils");
var import_constants = require("./constants.js");
var import_blob = require("./contracts/walrus/blob.js");
var metadata = __toESM(require("./contracts/walrus/metadata.js"));
var import_staking_inner = require("./contracts/walrus/staking_inner.js");
var import_staking_pool = require("./contracts/walrus/staking_pool.js");
var import_staking = require("./contracts/walrus/staking.js");
var import_storage_resource = require("./contracts/walrus/storage_resource.js");
var import_system_state_inner = require("./contracts/walrus/system_state_inner.js");
var import_system = require("./contracts/walrus/system.js");
var import_error = require("./error.js");
var import_client2 = require("./storage-node/client.js");
var import_error2 = require("./storage-node/error.js");
var import_bcs2 = require("./utils/bcs.js");
var import_utils2 = require("./utils/index.js");
var import_object_loader = require("./utils/object-loader.js");
var import_randomness = require("./utils/randomness.js");
var import_wasm = require("./wasm.js");
var import_utils3 = require("@mysten/utils");
var import_client3 = require("./upload-relay/client.js");
var import_quilts = require("./utils/quilts.js");
var import_blob2 = require("./files/readers/blob.js");
var import_blob3 = require("./files/blob.js");
var import_file = require("./files/file.js");
var import_quilt_file = require("./files/readers/quilt-file.js");
var import_quilt = require("./files/readers/quilt.js");
var import_retry = require("./utils/retry.js");
var _storageNodeClient, _wasmUrl, _packageConfig, _suiClient, _objectLoader, _blobMetadataConcurrencyLimit, _readCommittee, _cache, _uploadRelayConfig, _uploadRelayClient, _WalrusClient_instances, walType_fn, getPackageId_fn, getWalrusPackageId_fn, wasmBindings_fn, internalReadBlob_fn, getCertificationEpoch_fn, getReadCommittee_fn, forceGetReadCommittee_fn, withWal_fn, loadTipConfig_fn, getCreatedBlob_fn, writeBlobAttributesForRef_fn, executeTransaction_fn, getCommittee_fn, getActiveCommittee_fn, stakingPool_fn, getNodeByShardIndex_fn, retryOnPossibleEpochChange_fn;
function walrus({
  packageConfig,
  network,
  name = "walrus",
  ...options
} = {}) {
  return {
    name,
    register: (client) => {
      const walrusNetwork = network || client.network;
      if (walrusNetwork !== "mainnet" && walrusNetwork !== "testnet") {
        throw new import_error.WalrusClientError("Walrus client only supports mainnet and testnet");
      }
      return new WalrusClient(
        packageConfig ? {
          packageConfig,
          suiClient: client,
          ...options
        } : {
          network: walrusNetwork,
          suiClient: client,
          ...options
        }
      );
    }
  };
}
const _WalrusClient = class _WalrusClient {
  constructor(config) {
    __privateAdd(this, _WalrusClient_instances);
    __privateAdd(this, _storageNodeClient);
    __privateAdd(this, _wasmUrl);
    __privateAdd(this, _packageConfig);
    __privateAdd(this, _suiClient);
    __privateAdd(this, _objectLoader);
    __privateAdd(this, _blobMetadataConcurrencyLimit, 10);
    __privateAdd(this, _readCommittee);
    __privateAdd(this, _cache);
    __privateAdd(this, _uploadRelayConfig, null);
    __privateAdd(this, _uploadRelayClient, null);
    /** Read a blob from the storage nodes */
    this.readBlob = __privateMethod(this, _WalrusClient_instances, retryOnPossibleEpochChange_fn).call(this, __privateMethod(this, _WalrusClient_instances, internalReadBlob_fn));
    this.getSecondarySliver = __privateMethod(this, _WalrusClient_instances, retryOnPossibleEpochChange_fn).call(this, this.internalGetSecondarySliver);
    if (config.network && !config.packageConfig) {
      const network = config.network;
      switch (network) {
        case "testnet":
          __privateSet(this, _packageConfig, import_constants.TESTNET_WALRUS_PACKAGE_CONFIG);
          break;
        case "mainnet":
          __privateSet(this, _packageConfig, import_constants.MAINNET_WALRUS_PACKAGE_CONFIG);
          break;
        default:
          throw new import_error.WalrusClientError(`Unsupported network: ${network}`);
      }
    } else {
      __privateSet(this, _packageConfig, config.packageConfig);
    }
    __privateSet(this, _wasmUrl, config.wasmUrl);
    __privateSet(this, _uploadRelayConfig, config.uploadRelay ?? null);
    if (__privateGet(this, _uploadRelayConfig)) {
      __privateSet(this, _uploadRelayClient, new import_client3.UploadRelayClient(__privateGet(this, _uploadRelayConfig)));
    }
    __privateSet(this, _suiClient, config.suiClient ?? new import_client.SuiClient({
      url: config.suiRpcUrl
    }));
    __privateSet(this, _storageNodeClient, new import_client2.StorageNodeClient(config.storageNodeClientOptions));
    __privateSet(this, _objectLoader, new import_object_loader.SuiObjectDataLoader(__privateGet(this, _suiClient)));
    __privateSet(this, _cache, __privateGet(this, _suiClient).cache.scope("@mysten/walrus"));
  }
  /** @deprecated use `walrus()` instead */
  static experimental_asClientExtension({
    packageConfig,
    network,
    ...options
  } = {}) {
    return {
      name: "walrus",
      register: (client) => {
        const walrusNetwork = network || client.network;
        if (walrusNetwork !== "mainnet" && walrusNetwork !== "testnet") {
          throw new import_error.WalrusClientError("Walrus client only supports mainnet and testnet");
        }
        return new _WalrusClient(
          packageConfig ? {
            packageConfig,
            suiClient: client,
            ...options
          } : {
            network: walrusNetwork,
            suiClient: client,
            ...options
          }
        );
      }
    };
  }
  /** The Move type for a Blob object */
  getBlobType() {
    return __privateGet(this, _cache).read(["getBlobType"], async () => {
      return `${await __privateMethod(this, _WalrusClient_instances, getPackageId_fn).call(this)}::blob::Blob`;
    });
  }
  /** The cached system object for the walrus package */
  systemObject() {
    return __privateGet(this, _objectLoader).load(__privateGet(this, _packageConfig).systemObjectId, import_system.System);
  }
  /** The cached staking pool object for the walrus package */
  stakingObject() {
    return __privateGet(this, _objectLoader).load(__privateGet(this, _packageConfig).stakingPoolId, import_staking.Staking);
  }
  /** The system state for the current version of walrus contract  */
  async systemState() {
    const systemState = await __privateGet(this, _objectLoader).loadFieldObject(
      __privateGet(this, _packageConfig).systemObjectId,
      { type: "u64", value: (await this.systemObject()).version },
      import_system_state_inner.SystemStateInnerV1
    );
    return systemState;
  }
  /** The staking state for the current version of walrus contract */
  async stakingState() {
    return __privateGet(this, _objectLoader).loadFieldObject(
      __privateGet(this, _packageConfig).stakingPoolId,
      {
        type: "u64",
        value: (await this.stakingObject()).version
      },
      import_staking_inner.StakingInnerV1
    );
  }
  async computeBlobMetadata({ bytes, numShards }) {
    let shardCount;
    if (typeof numShards === "number") {
      shardCount = numShards;
    } else {
      const systemState = await this.systemState();
      shardCount = systemState.committee.n_shards;
    }
    const bindings = await __privateMethod(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const { blobId, metadata: metadata2, rootHash } = bindings.computeMetadata(shardCount, bytes);
    let sha256Hash;
    const nonce = crypto.getRandomValues(new Uint8Array(32));
    return {
      rootHash,
      blobId,
      metadata: {
        encodingType: metadata2.V1.encoding_type,
        hashes: Array.from(metadata2.V1.hashes).map((hashes) => ({
          primaryHash: hashes.primary_hash,
          secondaryHash: hashes.secondary_hash
        })),
        unencodedLength: metadata2.V1.unencoded_length
      },
      nonce,
      blobDigest: () => {
        if (!sha256Hash) {
          sha256Hash = crypto.subtle.digest("SHA-256", bytes).then((hash) => new Uint8Array(hash));
        }
        return sha256Hash;
      }
    };
  }
  async getBlobMetadata({ blobId, signal }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getReadCommittee_fn).call(this, { blobId, signal });
    const randomizedNodes = (0, import_randomness.shuffle)(committee.nodes);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    let numNotFoundWeight = 0;
    let numBlockedWeight = 0;
    let totalErrorCount = 0;
    const controller = new AbortController();
    const metadataExecutors = randomizedNodes.map((node) => async () => {
      try {
        return await __privateGet(this, _storageNodeClient).getBlobMetadata(
          { blobId },
          {
            nodeUrl: node.networkUrl,
            signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
          }
        );
      } catch (error) {
        if (error instanceof import_error2.NotFoundError) {
          numNotFoundWeight += node.shardIndices.length;
        } else if (error instanceof import_error2.LegallyUnavailableError) {
          numBlockedWeight += node.shardIndices.length;
        }
        totalErrorCount += 1;
        throw error;
      }
    });
    try {
      const attemptGetMetadata = metadataExecutors.shift();
      return await attemptGetMetadata();
    } catch {
      const chunkSize = Math.floor(metadataExecutors.length / __privateGet(this, _blobMetadataConcurrencyLimit));
      const chunkedExecutors = (0, import_utils3.chunk)(metadataExecutors, chunkSize);
      return await new Promise((resolve, reject) => {
        chunkedExecutors.forEach(async (executors) => {
          for (const executor of executors) {
            try {
              const result = await executor();
              controller.abort("Blob metadata successfully retrieved.");
              resolve(result);
            } catch (error) {
              if (error instanceof import_error2.UserAbortError) {
                reject(error);
                return;
              } else if ((0, import_utils2.isQuorum)(numBlockedWeight + numNotFoundWeight, numShards)) {
                const abortError = numNotFoundWeight > numBlockedWeight ? new import_error.BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`) : new import_error.BlobBlockedError(`The specified blob ${blobId} is blocked.`);
                controller.abort(abortError);
                reject(abortError);
                return;
              }
              if (totalErrorCount === metadataExecutors.length) {
                reject(
                  new import_error.NoBlobMetadataReceivedError(
                    "No valid blob metadata could be retrieved from any storage node."
                  )
                );
              }
            }
          }
        });
      });
    }
  }
  async internalGetSecondarySliver({ blobId, index, signal }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const sliverPairIndex = (0, import_utils2.sliverPairIndexFromSecondarySliverIndex)(index, numShards);
    const shardIndex = (0, import_utils2.toShardIndex)(sliverPairIndex, blobId, numShards);
    const node = await __privateMethod(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
    if (!node) {
      throw new Error(`No node found for shard index ${shardIndex}`);
    }
    const sliver = await __privateGet(this, _storageNodeClient).getSliver(
      { blobId, sliverPairIndex, sliverType: "secondary" },
      {
        nodeUrl: node.networkUrl,
        signal
      }
    );
    return sliver;
  }
  async getSlivers({ blobId, signal }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getReadCommittee_fn).call(this, { blobId, signal });
    const randomizedNodes = (0, import_randomness.weightedShuffle)(
      committee.nodes.map((node) => ({
        value: node,
        weight: node.shardIndices.length
      }))
    );
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const { primarySymbols: minSymbols } = (0, import_utils2.getSourceSymbols)(numShards);
    const sliverPairIndices = randomizedNodes.flatMap(
      (node) => node.shardIndices.map((shardIndex) => ({
        url: node.networkUrl,
        sliverPairIndex: (0, import_utils2.toPairIndex)(shardIndex, blobId, numShards)
      }))
    );
    const controller = new AbortController();
    const chunkedSliverPairIndices = (0, import_utils3.chunk)(sliverPairIndices, minSymbols);
    const slivers = [];
    const failedNodes = /* @__PURE__ */ new Set();
    let numNotFoundWeight = 0;
    let numBlockedWeight = 0;
    let totalErrorCount = 0;
    return new Promise((resolve, reject) => {
      chunkedSliverPairIndices[0].forEach(async (_, colIndex) => {
        for (let rowIndex = 0; rowIndex < chunkedSliverPairIndices.length; rowIndex += 1) {
          const value = chunkedSliverPairIndices.at(rowIndex)?.at(colIndex);
          if (!value) break;
          const { url, sliverPairIndex } = value;
          try {
            if (failedNodes.has(url)) {
              throw new Error(`Skipping node at ${url} due to previous failure.`);
            }
            const sliver = await __privateGet(this, _storageNodeClient).getSliver(
              { blobId, sliverPairIndex, sliverType: "primary" },
              {
                nodeUrl: url,
                signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
              }
            );
            if (slivers.length === minSymbols) {
              controller.abort("Enough slivers successfully retrieved.");
              resolve(slivers);
              return;
            }
            slivers.push(sliver);
          } catch (error) {
            if (error instanceof import_error2.NotFoundError) {
              numNotFoundWeight += 1;
            } else if (error instanceof import_error2.LegallyUnavailableError) {
              numBlockedWeight += 1;
            } else if (error instanceof import_error2.UserAbortError) {
              reject(error);
              return;
            }
            if ((0, import_utils2.isQuorum)(numBlockedWeight + numNotFoundWeight, numShards)) {
              const abortError = numNotFoundWeight > numBlockedWeight ? new import_error.BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`) : new import_error.BlobBlockedError(`The specified blob ${blobId} is blocked.`);
              controller.abort(abortError);
              reject(abortError);
              return;
            }
            failedNodes.add(url);
            totalErrorCount += 1;
            const remainingTasks = sliverPairIndices.length - (slivers.length + totalErrorCount);
            const tooManyFailures = slivers.length + remainingTasks < minSymbols;
            if (tooManyFailures) {
              const abortError = new import_error.NotEnoughSliversReceivedError(
                `Unable to retrieve enough slivers to decode blob ${blobId}.`
              );
              controller.abort(abortError);
              reject(abortError);
            }
          }
        }
      });
    });
  }
  /**
   * Gets the blob status from multiple storage nodes and returns the latest status that can be verified.
   */
  async getVerifiedBlobStatus({ blobId, signal }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const stakingState = await this.stakingState();
    const numShards = stakingState.n_shards;
    const controller = new AbortController();
    const statuses = await new Promise(
      (resolve, reject) => {
        const results = [];
        let successWeight = 0;
        let numNotFoundWeight = 0;
        let settledCount = 0;
        committee.nodes.forEach(async (node) => {
          const weight = node.shardIndices.length;
          try {
            const status = await __privateGet(this, _storageNodeClient).getBlobStatus(
              { blobId },
              {
                nodeUrl: node.networkUrl,
                signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal
              }
            );
            if ((0, import_utils2.isQuorum)(successWeight, numShards)) {
              controller.abort("Quorum of blob statuses retrieved successfully.");
              resolve(results);
            } else {
              successWeight += weight;
              results.push({ status, weight });
            }
          } catch (error) {
            if (error instanceof import_error2.NotFoundError) {
              numNotFoundWeight += weight;
            } else if (error instanceof import_error2.UserAbortError) {
              reject(error);
            }
            if ((0, import_utils2.isQuorum)(numNotFoundWeight, numShards)) {
              const abortError = new import_error.BlobNotCertifiedError("The blob does not exist.");
              controller.abort(abortError);
              reject(abortError);
            }
          } finally {
            settledCount += 1;
            if (settledCount === committee.nodes.length) {
              reject(
                new import_error.NoBlobStatusReceivedError(
                  "Not enough statuses were retrieved to achieve quorum."
                )
              );
            }
          }
        });
      }
    );
    const aggregatedStatuses = statuses.reduce((accumulator, value) => {
      const { status, weight } = value;
      const key = JSON.stringify(status);
      const existing = accumulator.get(key);
      if (existing) {
        existing.totalWeight += weight;
      } else {
        accumulator.set(key, { status, totalWeight: weight });
      }
      return accumulator;
    }, /* @__PURE__ */ new Map());
    const uniqueStatuses = [...aggregatedStatuses.values()];
    const sortedStatuses = uniqueStatuses.toSorted(
      (a, b) => import_constants.statusLifecycleRank[b.status.type] - import_constants.statusLifecycleRank[a.status.type]
    );
    for (const value of sortedStatuses) {
      if ((0, import_utils2.isAboveValidity)(value.totalWeight, numShards)) {
        return value.status;
      }
    }
    throw new import_error.NoVerifiedBlobStatusReceivedError(
      `The blob status could not be verified for blob ${blobId},`
    );
  }
  /**
   * Calculate the cost of storing a blob for a given a size and number of epochs.
   */
  async storageCost(size, epochs) {
    const systemState = await this.systemState();
    const encodedSize = (0, import_utils2.encodedBlobLength)(size, systemState.committee.n_shards);
    const storageUnits = (0, import_utils2.storageUnitsFromSize)(encodedSize);
    const storageCost = BigInt(storageUnits) * BigInt(systemState.storage_price_per_unit_size) * BigInt(epochs);
    BigInt(epochs);
    const writeCost = BigInt(storageUnits) * BigInt(systemState.write_price_per_unit_size);
    return { storageCost, writeCost, totalCost: storageCost + writeCost };
  }
  /**
   * A utility for creating a storage object in a transaction.
   *
   * @example
   * ```ts
   * tx.transferObjects([client.createStorage({ size: 1000, epochs: 3 })], owner);
   * ```
   */
  createStorage({ size, epochs, walCoin }) {
    return async (tx) => {
      const systemObject = await this.systemObject();
      const systemState = await this.systemState();
      const encodedSize = (0, import_utils2.encodedBlobLength)(size, systemState.committee.n_shards);
      const [{ storageCost }, walrusPackageId] = await Promise.all([
        this.storageCost(size, epochs),
        __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this)
      ]);
      return tx.add(
        __privateMethod(this, _WalrusClient_instances, withWal_fn).call(this, storageCost, walCoin ?? null, (coin, tx2) => {
          return tx2.add(
            (0, import_system.reserveSpace)({
              package: walrusPackageId,
              arguments: {
                self: systemObject.id.id,
                storageAmount: encodedSize,
                epochsAhead: epochs,
                payment: coin
              }
            })
          );
        })
      );
    };
  }
  /**
   * Create a transaction that creates a storage object
   *
   * @example
   * ```ts
   * const tx = client.createStorageTransaction({ size: 1000, epochs: 3, owner: signer.toSuiAddress() });
   * ```
   */
  createStorageTransaction({
    transaction = new import_transactions.Transaction(),
    size,
    epochs,
    owner
  }) {
    transaction.transferObjects([this.createStorage({ size, epochs })], owner);
    return transaction;
  }
  /**
   * Execute a transaction that creates a storage object
   *
   * @example
   * ```ts
   * const { digest, storage } = await client.executeCreateStorageTransaction({ size: 1000, epochs: 3, signer });
   * ```
   */
  async executeCreateStorageTransaction({
    signer,
    ...options
  }) {
    const transaction = this.createStorageTransaction({
      ...options,
      owner: options.transaction?.getData().sender ?? signer.toSuiAddress()
    });
    const blobType = await this.getBlobType();
    const { digest, effects } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "create storage");
    const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
    const createdObjects = await __privateGet(this, _suiClient).core.getObjects({
      objectIds: createdObjectIds
    });
    const suiBlobObject = createdObjects.objects.find(
      (object) => !(object instanceof Error) && object.type === blobType
    );
    if (suiBlobObject instanceof Error || !suiBlobObject) {
      throw new import_error.WalrusClientError(
        `Storage object not found in transaction effects for transaction (${digest})`
      );
    }
    return {
      digest,
      storage: import_storage_resource.Storage.parse(await suiBlobObject.content)
    };
  }
  /**
   * Register a blob in a transaction
   *
   * @example
   * ```ts
   * tx.transferObjects([client.registerBlob({ size: 1000, epochs: 3, blobId, rootHash, deletable: true })], owner);
   * ```
   */
  registerBlob({
    size,
    epochs,
    blobId,
    rootHash,
    deletable,
    walCoin,
    attributes
  }) {
    return async (tx) => {
      const { writeCost } = await this.storageCost(size, epochs);
      const walrusPackageId = await __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      return tx.add(
        __privateMethod(this, _WalrusClient_instances, withWal_fn).call(this, writeCost, walCoin ?? null, async (writeCoin, tx2) => {
          const blob = tx2.add(
            (0, import_system.registerBlob)({
              package: walrusPackageId,
              arguments: {
                self: tx2.object(__privateGet(this, _packageConfig).systemObjectId),
                storage: this.createStorage({ size, epochs, walCoin }),
                blobId: (0, import_bcs2.blobIdToInt)(blobId),
                rootHash: BigInt(import_bcs.bcs.u256().parse(rootHash)),
                size,
                encodingType: 1,
                deletable,
                writePayment: writeCoin
              }
            })
          );
          if (attributes) {
            tx2.add(
              __privateMethod(this, _WalrusClient_instances, writeBlobAttributesForRef_fn).call(this, {
                attributes,
                existingAttributes: null,
                blob
              })
            );
          }
          return blob;
        })
      );
    };
  }
  addAuthPayload({
    size,
    blobDigest,
    nonce
  }) {
    return async (transaction) => {
      const nonceDigest = await crypto.subtle.digest("SHA-256", nonce);
      const lengthBytes = import_bcs.bcs.u64().serialize(size).toBytes();
      const digest = typeof blobDigest === "function" ? await blobDigest() : blobDigest;
      const authPayload = new Uint8Array(
        nonceDigest.byteLength + digest.byteLength + lengthBytes.byteLength
      );
      authPayload.set(digest, 0);
      authPayload.set(new Uint8Array(nonceDigest), digest.byteLength);
      authPayload.set(lengthBytes, nonceDigest.byteLength + digest.byteLength);
      transaction.pure(authPayload);
    };
  }
  async calculateUploadRelayTip(options) {
    const systemState = await this.systemState();
    const encodedSize = (0, import_utils2.encodedBlobLength)(options.size, systemState.committee.n_shards);
    const tipConfig = await __privateMethod(this, _WalrusClient_instances, loadTipConfig_fn).call(this);
    if (!tipConfig) {
      return 0n;
    }
    const { max, kind } = tipConfig;
    const amount = "const" in kind ? kind.const : BigInt(kind.linear.base) + BigInt(kind.linear.perEncodedKib) * ((BigInt(encodedSize) + 1023n) / 1024n);
    if (max != null && amount > max) {
      throw new import_error.WalrusClientError(
        `Tip amount (${amount}) exceeds the maximum allowed tip (${max})`
      );
    }
    return amount;
  }
  sendUploadRelayTip({
    size,
    blobDigest,
    nonce
  }) {
    return async (transaction) => {
      const tipConfig = await __privateMethod(this, _WalrusClient_instances, loadTipConfig_fn).call(this);
      if (tipConfig) {
        transaction.add(this.addAuthPayload({ size, blobDigest, nonce }));
        const amount = await this.calculateUploadRelayTip({ size });
        const { address } = tipConfig;
        transaction.transferObjects(
          [
            (0, import_transactions.coinWithBalance)({
              balance: amount
            })
          ],
          address
        );
      }
    };
  }
  /**
   * Create a transaction that registers a blob
   *
   * @example
   * ```ts
   * const tx = client.registerBlobTransaction({ size: 1000, epochs: 3, blobId, rootHash, deletable: true });
   * ```
   */
  registerBlobTransaction({
    transaction = new import_transactions.Transaction(),
    ...options
  }) {
    const registration = transaction.add(this.registerBlob(options));
    transaction.transferObjects([registration], options.owner);
    return transaction;
  }
  /**
   * Execute a transaction that registers a blob
   *
   * @example
   * ```ts
   * const { digest, blob } = await client.executeRegisterBlobTransaction({ size: 1000, epochs: 3, signer });
   * ```
   */
  async executeRegisterBlobTransaction({
    signer,
    ...options
  }) {
    const transaction = this.registerBlobTransaction({
      ...options,
      owner: options.owner ?? options.transaction?.getData().sender ?? signer.toSuiAddress()
    });
    const blobType = await this.getBlobType();
    const { digest, effects } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "register blob");
    const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
    const createdObjects = await __privateGet(this, _suiClient).core.getObjects({
      objectIds: createdObjectIds
    });
    const suiBlobObject = createdObjects.objects.find(
      (object) => !(object instanceof Error) && object.type === blobType
    );
    if (suiBlobObject instanceof Error || !suiBlobObject) {
      throw new import_error.WalrusClientError(
        `Blob object not found in transaction effects for transaction (${digest})`
      );
    }
    return {
      digest,
      blob: import_blob.Blob.parse(await suiBlobObject.content)
    };
  }
  async certificateFromConfirmations({
    confirmations,
    blobId,
    deletable,
    blobObjectId
  }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    if (confirmations.length !== systemState.committee.members.length) {
      throw new import_error.WalrusClientError(
        "Invalid number of confirmations. Confirmations array must contain an entry for each node"
      );
    }
    const confirmationMessage = import_bcs2.StorageConfirmation.serialize({
      intent: import_bcs2.IntentType.BLOB_CERT_MSG,
      epoch: systemState.committee.epoch,
      messageContents: {
        blobId,
        blobType: deletable ? {
          Deletable: {
            objectId: blobObjectId
          }
        } : {
          Permanent: null
        }
      }
    }).toBase64();
    const bindings = await __privateMethod(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const verifySignature = bindings.getVerifySignature();
    const filteredConfirmations = confirmations.map((confirmation, index) => {
      const isValid = confirmation?.serializedMessage === confirmationMessage && verifySignature(
        confirmation,
        new Uint8Array(committee.nodes[index].info.public_key.bytes)
      );
      return isValid ? {
        index,
        ...confirmation
      } : null;
    }).filter((confirmation) => confirmation !== null);
    if (!(0, import_utils2.isQuorum)(filteredConfirmations.length, systemState.committee.members.length)) {
      throw new import_error.NotEnoughBlobConfirmationsError(
        `Too many invalid confirmations received for blob (${filteredConfirmations.length} of ${systemState.committee.members.length})`
      );
    }
    return bindings.combineSignatures(
      filteredConfirmations,
      filteredConfirmations.map(({ index }) => index)
    );
  }
  /**
   * Certify a blob in a transaction
   *
   * @example
   * ```ts
   * tx.add(client.certifyBlob({ blobId, blobObjectId, confirmations }));
   * ```
   */
  certifyBlob({ blobId, blobObjectId, confirmations, certificate, deletable }) {
    return async (tx) => {
      const systemState = await this.systemState();
      const combinedSignature = certificate ?? await this.certificateFromConfirmations({
        confirmations,
        blobId,
        deletable,
        blobObjectId
      });
      const walrusPackageId = await __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      tx.add(
        (0, import_system.certifyBlob)({
          package: walrusPackageId,
          arguments: {
            self: __privateGet(this, _packageConfig).systemObjectId,
            blob: blobObjectId,
            signature: tx.pure.vector("u8", combinedSignature.signature),
            signersBitmap: tx.pure.vector(
              "u8",
              (0, import_utils2.signersToBitmap)(combinedSignature.signers, systemState.committee.members.length)
            ),
            message: tx.pure.vector("u8", combinedSignature.serializedMessage)
          }
        })
      );
    };
  }
  /**
   * Create a transaction that certifies a blob
   *
   * @example
   * ```ts
   * const tx = client.certifyBlobTransaction({ blobId, blobObjectId, confirmations });
   * ```
   */
  certifyBlobTransaction({
    transaction = new import_transactions.Transaction(),
    ...options
  }) {
    transaction.add(this.certifyBlob(options));
    return transaction;
  }
  /**
   * Execute a transaction that certifies a blob
   *
   * @example
   * ```ts
   * const { digest } = await client.executeCertifyBlobTransaction({ blobId, blobObjectId, confirmations, signer });
   * ```
   */
  async executeCertifyBlobTransaction({
    signer,
    ...options
  }) {
    const transaction = this.certifyBlobTransaction(options);
    const { digest } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, transaction, signer, "certify blob");
    return { digest };
  }
  /**
   * Delete a blob in a transaction
   *
   * @example
   * ```ts
   * const storage = await client.deleteBlob({ blobObjectId });
   * tx.transferObjects([storage], owner);
   * ```
   */
  deleteBlob({ blobObjectId }) {
    return async (tx) => {
      const walrusPackageId = await __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      const storage = tx.add(
        (0, import_system.deleteBlob)({
          package: walrusPackageId,
          arguments: {
            self: __privateGet(this, _packageConfig).systemObjectId,
            blob: blobObjectId
          }
        })
      );
      return storage;
    };
  }
  /**
   * Create a transaction that deletes a blob
   *
   * @example
   * ```ts
   * const tx = client.deleteBlobTransaction({ blobObjectId, owner });
   * ```
   */
  deleteBlobTransaction({
    owner,
    blobObjectId,
    transaction = new import_transactions.Transaction()
  }) {
    const storage = transaction.add(this.deleteBlob({ blobObjectId }));
    transaction.transferObjects([storage], owner);
    return transaction;
  }
  /**
   * Execute a transaction that deletes a blob
   *
   * @example
   * ```ts
   * const { digest } = await client.executeDeleteBlobTransaction({ blobObjectId, signer });
   * ```
   */
  async executeDeleteBlobTransaction({
    signer,
    transaction = new import_transactions.Transaction(),
    blobObjectId
  }) {
    const { digest } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, this.deleteBlobTransaction({
      blobObjectId,
      transaction,
      owner: transaction.getData().sender ?? signer.toSuiAddress()
    }), signer, "delete blob");
    return { digest };
  }
  /**
   * Extend a blob in a transaction
   *
   * @example
   * ```ts
   * const tx = client.extendBlobTransaction({ blobObjectId, epochs });
   * ```
   */
  extendBlob({ blobObjectId, epochs, endEpoch, walCoin }) {
    return async (tx) => {
      const blob = await __privateGet(this, _objectLoader).load(blobObjectId, import_blob.Blob);
      const numEpochs = typeof epochs === "number" ? epochs : endEpoch - blob.storage.end_epoch;
      if (numEpochs <= 0) {
        return;
      }
      const { storageCost } = await this.storageCost(Number(blob.storage.storage_size), numEpochs);
      const walrusPackageId = await __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
      return tx.add(
        __privateMethod(this, _WalrusClient_instances, withWal_fn).call(this, storageCost, walCoin ?? null, async (coin, tx2) => {
          tx2.add(
            (0, import_system.extendBlob)({
              package: walrusPackageId,
              arguments: {
                self: __privateGet(this, _packageConfig).systemObjectId,
                blob: blobObjectId,
                extendedEpochs: numEpochs,
                payment: coin
              }
            })
          );
        })
      );
    };
  }
  /**
   * Create a transaction that extends a blob
   *
   * @example
   * ```ts
   * const tx = client.extendBlobTransaction({ blobObjectId, epochs });
   * ```
   */
  async extendBlobTransaction({
    transaction = new import_transactions.Transaction(),
    ...options
  }) {
    transaction.add(this.extendBlob(options));
    return transaction;
  }
  /**
   * Execute a transaction that extends a blob
   *
   * @example
   * ```ts
   * const { digest } = await client.executeExtendBlobTransaction({ blobObjectId, signer });
   * ```
   */
  async executeExtendBlobTransaction({
    signer,
    ...options
  }) {
    const { digest } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, await this.extendBlobTransaction(options), signer, "extend blob");
    return { digest };
  }
  async readBlobAttributes({
    blobObjectId
  }) {
    const response = await __privateGet(this, _suiClient).core.getDynamicField({
      parentId: blobObjectId,
      name: {
        type: "vector<u8>",
        bcs: import_bcs.bcs.string().serialize("metadata").toBytes()
      }
    });
    const parsedMetadata = metadata.Metadata.parse(response.dynamicField.value.bcs);
    return Object.fromEntries(
      parsedMetadata.metadata.contents.map(({ key, value }) => [key, value])
    );
  }
  /**
   * Write attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @example
   * ```ts
   * tx.add(client.writeBlobAttributes({ blobObjectId, attributes: { key: 'value', keyToRemove: null } }));
   * ```
   */
  writeBlobAttributes({ blobObject, blobObjectId, attributes }) {
    return async (tx) => {
      const existingAttributes = blobObjectId ? await this.readBlobAttributes({ blobObjectId }) : null;
      const blob = blobObject ?? tx.object(blobObjectId);
      tx.add(
        __privateMethod(this, _WalrusClient_instances, writeBlobAttributesForRef_fn).call(this, {
          attributes,
          existingAttributes,
          blob
        })
      );
    };
  }
  /**
   * Create a transaction that writes attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @example
   * ```ts
   * const tx = client.writeBlobAttributesTransaction({ blobObjectId, attributes: { key: 'value', keyToRemove: null } });
   * ```
   */
  async writeBlobAttributesTransaction({
    transaction = new import_transactions.Transaction(),
    ...options
  }) {
    transaction.add(await this.writeBlobAttributes(options));
    return transaction;
  }
  /**
   * Execute a transaction that writes attributes to a blob
   *
   * If attributes already exists, their previous values will be overwritten
   * If an attribute is set to `null`, it will be removed from the blob
   *
   * @example
   * ```ts
   * const { digest } = await client.executeWriteBlobAttributesTransaction({ blobObjectId, signer });
   * ```
   */
  async executeWriteBlobAttributesTransaction({
    signer,
    ...options
  }) {
    const { digest } = await __privateMethod(this, _WalrusClient_instances, executeTransaction_fn).call(this, await this.writeBlobAttributesTransaction(options), signer, "write blob attributes");
    return { digest };
  }
  /**
   * Write a sliver to a storage node
   *
   * @example
   * ```ts
   * const res = await client.writeSliver({ blobId, sliverPairIndex, sliverType, sliver });
   * ```
   */
  async writeSliver({ blobId, sliverPairIndex, sliverType, sliver, signal }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const shardIndex = (0, import_utils2.toShardIndex)(sliverPairIndex, blobId, systemState.committee.n_shards);
    const node = await __privateMethod(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
    return __privateGet(this, _storageNodeClient).storeSliver(
      { blobId, sliverPairIndex, sliverType, sliver },
      { nodeUrl: node.networkUrl, signal }
    );
  }
  /**
   * Write metadata to a storage node
   *
   * @example
   * ```ts
   * const res = await client.writeMetadataToNode({ nodeIndex, blobId, metadata });
   * ```
   */
  async writeMetadataToNode({ nodeIndex, blobId, metadata: metadata2, signal }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const node = committee.nodes[nodeIndex];
    return (0, import_retry.retry)(
      () => __privateGet(this, _storageNodeClient).storeBlobMetadata(
        { blobId, metadata: metadata2 },
        { nodeUrl: node.networkUrl, signal }
      ),
      {
        count: 3,
        delay: 1e3,
        condition: (error) => error instanceof import_error2.BlobNotRegisteredError
      }
    );
  }
  /**
   * Get a storage confirmation from a storage node
   *
   * @example
   * ```ts
   * const confirmation = await client.getStorageConfirmationFromNode({ nodeIndex, blobId, deletable, objectId });
   * ```
   */
  async getStorageConfirmationFromNode({
    nodeIndex,
    blobId,
    deletable,
    objectId,
    signal
  }) {
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const node = committee.nodes[nodeIndex];
    const result = deletable ? await __privateGet(this, _storageNodeClient).getDeletableBlobConfirmation(
      { blobId, objectId },
      { nodeUrl: node.networkUrl, signal }
    ) : await __privateGet(this, _storageNodeClient).getPermanentBlobConfirmation(
      { blobId },
      { nodeUrl: node.networkUrl, signal }
    );
    return result?.success?.data?.signed ?? null;
  }
  /**
   * Encode a blob into slivers for each node
   *
   * @example
   * ```ts
   * const { blobId, metadata, sliversByNode, rootHash } = await client.encodeBlob(blob);
   * ```
   */
  async encodeBlob(blob) {
    const systemState = await this.systemState();
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const numShards = systemState.committee.n_shards;
    const bindings = await __privateMethod(this, _WalrusClient_instances, wasmBindings_fn).call(this);
    const { blobId, metadata: metadata2, sliverPairs, rootHash } = bindings.encodeBlob(numShards, blob);
    const sliversByNodeMap = /* @__PURE__ */ new Map();
    while (sliverPairs.length > 0) {
      const { primary, secondary } = sliverPairs.pop();
      const sliverPairIndex = primary.index;
      const shardIndex = (0, import_utils2.toShardIndex)(sliverPairIndex, blobId, numShards);
      const node = await __privateMethod(this, _WalrusClient_instances, getNodeByShardIndex_fn).call(this, committee, shardIndex);
      if (!sliversByNodeMap.has(node.nodeIndex)) {
        sliversByNodeMap.set(node.nodeIndex, { primary: [], secondary: [] });
      }
      sliversByNodeMap.get(node.nodeIndex).primary.push({
        sliverIndex: primary.index,
        sliverPairIndex,
        shardIndex,
        sliver: import_bcs2.SliverData.serialize(primary).toBytes()
      });
      sliversByNodeMap.get(node.nodeIndex).secondary.push({
        sliverIndex: secondary.index,
        sliverPairIndex,
        shardIndex,
        sliver: import_bcs2.SliverData.serialize(secondary).toBytes()
      });
    }
    const sliversByNode = new Array();
    for (let i = 0; i < systemState.committee.members.length; i++) {
      sliversByNode.push(sliversByNodeMap.get(i) ?? { primary: [], secondary: [] });
    }
    return { blobId, metadata: metadata2, rootHash, sliversByNode };
  }
  /**
   * Write slivers to a storage node
   *
   * @example
   * ```ts
   * await client.writeSliversToNode({ blobId, slivers, signal });
   * ```
   */
  async writeSliversToNode({ blobId, slivers, signal }) {
    const controller = new AbortController();
    const combinedSignal = signal ? AbortSignal.any([controller.signal, signal]) : controller.signal;
    const primarySliverWrites = slivers.primary.map(({ sliverPairIndex, sliver }) => {
      return this.writeSliver({
        blobId,
        sliverPairIndex,
        sliverType: "primary",
        sliver,
        signal: combinedSignal
      });
    });
    const secondarySliverWrites = slivers.secondary.map(({ sliverPairIndex, sliver }) => {
      return this.writeSliver({
        blobId,
        sliverPairIndex,
        sliverType: "secondary",
        sliver,
        signal: combinedSignal
      });
    });
    await Promise.all([...primarySliverWrites, ...secondarySliverWrites]).catch((error) => {
      controller.abort(error);
      throw error;
    });
  }
  /**
   * Write a blob to all storage nodes
   *
   * @example
   * ```ts
   * await client.writeEncodedBlobToNodes({ blob, deletable, epochs, signer });
   * ```
   */
  async writeEncodedBlobToNodes({
    blobId,
    metadata: metadata2,
    sliversByNode,
    signal,
    ...options
  }) {
    const systemState = await this.systemState();
    const committee = await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
    const controller = new AbortController();
    let failures = 0;
    const confirmations = await Promise.all(
      sliversByNode.map((slivers, nodeIndex) => {
        return this.writeEncodedBlobToNode({
          blobId,
          nodeIndex,
          metadata: metadata2,
          slivers,
          signal: signal ? AbortSignal.any([controller.signal, signal]) : controller.signal,
          ...options
        }).catch(() => {
          failures += committee.nodes[nodeIndex].shardIndices.length;
          if ((0, import_utils2.isAboveValidity)(failures, systemState.committee.n_shards)) {
            const error = new import_error.NotEnoughBlobConfirmationsError(
              `Too many failures while writing blob ${blobId} to nodes`
            );
            controller.abort(error);
            throw error;
          }
          return null;
        });
      })
    );
    return confirmations;
  }
  /**
   * Writes a blob to to an upload relay
   *
   * @example
   * ```ts
   * await client.writeBlobToUploadRelay({ blob, deletable, epochs, signer });
   * ```
   */
  async writeBlobToUploadRelay(options) {
    if (!__privateGet(this, _uploadRelayClient)) {
      throw new import_error.WalrusClientError("Upload relay not configured");
    }
    return __privateGet(this, _uploadRelayClient).writeBlob({
      ...options,
      requiresTip: !!__privateGet(this, _uploadRelayConfig)?.sendTip
    });
  }
  /**
   * Write encoded blob to a storage node
   *
   * @example
   * ```ts
   * const res = await client.writeEncodedBlobToNode({ nodeIndex, blobId, metadata, slivers });
   * ```
   */
  async writeEncodedBlobToNode({
    nodeIndex,
    blobId,
    metadata: metadata2,
    slivers,
    signal,
    ...options
  }) {
    await this.writeMetadataToNode({
      nodeIndex,
      blobId,
      metadata: metadata2,
      signal
    });
    await this.writeSliversToNode({ blobId, slivers, signal, nodeIndex });
    return this.getStorageConfirmationFromNode({
      nodeIndex,
      blobId,
      ...options
    });
  }
  /**
   * Write a blob to all storage nodes
   *
   * @example
   * ```ts
   * const { blobId, blobObject } = await client.writeBlob({ blob, deletable, epochs, signer });
   * ```
   */
  async writeBlob({
    blob,
    deletable,
    epochs,
    signer,
    signal,
    owner,
    attributes
  }) {
    if (!__privateGet(this, _uploadRelayConfig)) {
      const encoded = await this.encodeBlob(blob);
      const blobId = encoded.blobId;
      const { sliversByNode, metadata: metadata2, rootHash } = encoded;
      const suiBlobObject = await this.executeRegisterBlobTransaction({
        signer,
        size: blob.length,
        epochs,
        blobId,
        rootHash,
        deletable,
        owner: owner ?? signer.toSuiAddress(),
        attributes
      });
      const blobObjectId = suiBlobObject.blob.id.id;
      const confirmations = await this.writeEncodedBlobToNodes({
        blobId,
        metadata: metadata2,
        sliversByNode,
        deletable,
        objectId: blobObjectId,
        signal
      });
      await this.executeCertifyBlobTransaction({
        signer,
        blobId,
        blobObjectId,
        confirmations,
        deletable
      });
      return {
        blobId,
        blobObject: await __privateGet(this, _objectLoader).load(blobObjectId, import_blob.Blob)
      };
    } else {
      const metadata2 = await this.computeBlobMetadata({
        bytes: blob
      });
      const blobId = metadata2.blobId;
      const transaction = new import_transactions.Transaction();
      transaction.add(
        this.sendUploadRelayTip({
          size: blob.length,
          blobDigest: metadata2.blobDigest,
          nonce: metadata2.nonce
        })
      );
      const registerResult = await this.executeRegisterBlobTransaction({
        signer,
        transaction,
        size: blob.length,
        epochs,
        blobId: metadata2.blobId,
        rootHash: metadata2.rootHash,
        deletable,
        owner: owner ?? signer.toSuiAddress(),
        attributes
      });
      await __privateGet(this, _suiClient).core.waitForTransaction({
        digest: registerResult.digest
      });
      const result = await this.writeBlobToUploadRelay({
        blobId,
        blob,
        nonce: metadata2.nonce,
        txDigest: registerResult.digest,
        signal,
        deletable,
        blobObjectId: registerResult.blob.id.id,
        encodingType: metadata2.metadata.encodingType
      });
      const certificate = result.certificate;
      const blobObjectId = registerResult.blob.id.id;
      await this.executeCertifyBlobTransaction({
        signer,
        blobId,
        blobObjectId,
        certificate,
        deletable
      });
      return {
        blobId,
        blobObject: await __privateGet(this, _objectLoader).load(blobObjectId, import_blob.Blob)
      };
    }
  }
  async writeQuilt({ blobs, ...options }) {
    const encoded = await this.encodeQuilt({ blobs });
    const result = await this.writeBlob({
      ...options,
      blob: encoded.quilt,
      attributes: {
        _walrusBlobType: "quilt",
        ...options.attributes
      }
    });
    return {
      ...result,
      index: {
        ...encoded.index,
        patches: encoded.index.patches.map((patch) => ({
          ...patch,
          patchId: (0, import_quilts.encodeQuiltPatchId)({
            quiltId: result.blobId,
            patchId: {
              version: 1,
              startIndex: patch.startIndex,
              endIndex: patch.endIndex
            }
          })
        }))
      }
    };
  }
  async encodeQuilt({
    blobs
  }) {
    const systemState = await this.systemState();
    const encoded = (0, import_quilts.encodeQuilt)({
      blobs,
      numShards: systemState.committee.n_shards
    });
    return encoded;
  }
  /**
   * Reset cached data in the client
   *
   * @example
   * ```ts
   * client.reset();
   * ```
   */
  reset() {
    __privateGet(this, _objectLoader).clearAll();
    __privateGet(this, _cache).clear();
  }
  async getBlob({ blobId }) {
    return new import_blob3.WalrusBlob({
      reader: new import_blob2.BlobReader({
        client: this,
        blobId,
        numShards: (await this.systemState()).committee.n_shards
      }),
      client: this
    });
  }
  async getFiles({ ids }) {
    const readersByBlobId = /* @__PURE__ */ new Map();
    const quiltReadersByBlobId = /* @__PURE__ */ new Map();
    const parsedIds = ids.map((id) => (0, import_quilts.parseWalrusId)(id));
    const numShards = (await this.systemState()).committee.n_shards;
    for (const id of parsedIds) {
      const blobId = id.kind === "blob" ? id.id : id.id.quiltId;
      if (!readersByBlobId.has(blobId)) {
        readersByBlobId.set(
          blobId,
          new import_blob2.BlobReader({
            client: this,
            blobId,
            numShards
          })
        );
      }
      if (id.kind === "quiltPatch") {
        if (!quiltReadersByBlobId.has(blobId)) {
          quiltReadersByBlobId.set(
            blobId,
            new import_quilt.QuiltReader({
              blob: readersByBlobId.get(blobId)
            })
          );
        }
      }
    }
    return parsedIds.map((id) => {
      if (id.kind === "blob") {
        return new import_file.WalrusFile({
          reader: readersByBlobId.get(id.id)
        });
      }
      return new import_file.WalrusFile({
        reader: new import_quilt_file.QuiltFileReader({
          quilt: quiltReadersByBlobId.get(id.id.quiltId),
          sliverIndex: id.id.patchId.startIndex
        })
      });
    });
  }
  async writeFiles({ files, ...options }) {
    const { blobId, index, blobObject } = await this.writeQuilt({
      ...options,
      blobs: await Promise.all(
        files.map(async (file, i) => ({
          contents: await file.bytes(),
          identifier: await file.getIdentifier() ?? `file-${i}`,
          tags: await file.getTags() ?? {}
        }))
      )
    });
    return index.patches.map((patch) => ({
      id: patch.patchId,
      blobId,
      blobObject
    }));
  }
  writeFilesFlow({ files }) {
    const encode = async () => {
      const { quilt, index } = await this.encodeQuilt({
        blobs: await Promise.all(
          files.map(async (file, i) => ({
            contents: await file.bytes(),
            identifier: await file.getIdentifier() ?? `file-${i}`,
            tags: await file.getTags() ?? {}
          }))
        )
      });
      const metadata2 = __privateGet(this, _uploadRelayClient) ? await this.computeBlobMetadata({
        bytes: quilt
      }) : await this.encodeBlob(quilt);
      return {
        metadata: metadata2,
        size: quilt.length,
        data: __privateGet(this, _uploadRelayClient) ? quilt : void 0,
        index
      };
    };
    const register = ({ data, metadata: metadata2, index, size }, { epochs, deletable, owner, attributes }) => {
      const transaction = new import_transactions.Transaction();
      transaction.setSenderIfNotSet(owner);
      if (__privateGet(this, _uploadRelayClient)) {
        const meta = metadata2;
        transaction.add(
          this.sendUploadRelayTip({
            size,
            blobDigest: meta.blobDigest,
            nonce: meta.nonce
          })
        );
      }
      transaction.transferObjects(
        [
          this.registerBlob({
            size,
            epochs,
            blobId: metadata2.blobId,
            rootHash: metadata2.rootHash,
            deletable,
            attributes: {
              _walrusBlobType: "quilt",
              ...attributes
            }
          })
        ],
        owner
      );
      return {
        registerTransaction: transaction,
        index,
        data,
        metadata: metadata2,
        deletable
      };
    };
    const upload = async ({ index, data, metadata: metadata2, deletable }, { digest }) => {
      const blobObject = await __privateMethod(this, _WalrusClient_instances, getCreatedBlob_fn).call(this, digest);
      if (__privateGet(this, _uploadRelayClient)) {
        const meta2 = metadata2;
        return {
          index,
          blobObject,
          metadata: metadata2,
          deletable,
          certificate: (await this.writeBlobToUploadRelay({
            blobId: metadata2.blobId,
            blob: data,
            nonce: meta2.nonce,
            txDigest: digest,
            blobObjectId: blobObject.id.id,
            deletable,
            encodingType: meta2.metadata.encodingType
          })).certificate
        };
      }
      const meta = metadata2;
      return {
        index,
        blobObject,
        metadata: metadata2,
        deletable,
        confirmations: await this.writeEncodedBlobToNodes({
          blobId: metadata2.blobId,
          objectId: blobObject.id.id,
          metadata: meta.metadata,
          sliversByNode: meta.sliversByNode,
          deletable
        })
      };
    };
    const certify = ({
      index,
      metadata: metadata2,
      confirmations,
      certificate,
      blobObject,
      deletable
    }) => {
      return {
        index,
        blobObject,
        metadata: metadata2,
        transaction: confirmations ? this.certifyBlobTransaction({
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          confirmations,
          deletable
        }) : this.certifyBlobTransaction({
          certificate,
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          deletable
        })
      };
    };
    async function listFiles({ index, blobObject, metadata: metadata2 }) {
      return index.patches.map((patch) => ({
        id: (0, import_quilts.encodeQuiltPatchId)({
          quiltId: metadata2.blobId,
          patchId: {
            version: 1,
            startIndex: patch.startIndex,
            endIndex: patch.endIndex
          }
        }),
        blobId: metadata2.blobId,
        blobObject
      }));
    }
    const stepResults = {};
    function getResults(step, current) {
      if (!stepResults[step]) {
        throw new Error(`${step} must be executed before calling ${current}`);
      }
      return stepResults[step];
    }
    return {
      encode: async () => {
        if (!stepResults.encode) {
          stepResults.encode = await encode();
        }
      },
      register: (options) => {
        stepResults.register = register(getResults("encode", "register"), options);
        return stepResults.register.registerTransaction;
      },
      upload: async (options) => {
        stepResults.upload = await upload(getResults("register", "upload"), options);
      },
      certify: () => {
        stepResults.certify = certify(getResults("upload", "certify"));
        return stepResults.certify.transaction;
      },
      listFiles: async () => {
        return listFiles(getResults("certify", "listFiles"));
      }
    };
  }
  writeBlobFlow({ blob }) {
    const encode = async () => {
      const metadata2 = __privateGet(this, _uploadRelayClient) ? await this.computeBlobMetadata({
        bytes: blob
      }) : await this.encodeBlob(blob);
      return {
        metadata: metadata2,
        size: blob.length,
        data: __privateGet(this, _uploadRelayClient) ? blob : void 0
      };
    };
    const register = ({ data, metadata: metadata2, size }, { epochs, deletable, owner, attributes }) => {
      const transaction = new import_transactions.Transaction();
      transaction.setSenderIfNotSet(owner);
      if (__privateGet(this, _uploadRelayClient)) {
        const meta = metadata2;
        transaction.add(
          this.sendUploadRelayTip({
            size,
            blobDigest: meta.blobDigest,
            nonce: meta.nonce
          })
        );
      }
      transaction.transferObjects(
        [
          this.registerBlob({
            size,
            epochs,
            blobId: metadata2.blobId,
            rootHash: metadata2.rootHash,
            deletable,
            attributes
          })
        ],
        owner
      );
      return {
        registerTransaction: transaction,
        data,
        metadata: metadata2,
        deletable
      };
    };
    const upload = async ({ data, metadata: metadata2, deletable }, { digest }) => {
      const blobObject = await __privateMethod(this, _WalrusClient_instances, getCreatedBlob_fn).call(this, digest);
      if (__privateGet(this, _uploadRelayClient)) {
        const meta2 = metadata2;
        return {
          blobObject,
          metadata: metadata2,
          deletable,
          certificate: (await this.writeBlobToUploadRelay({
            blobId: metadata2.blobId,
            blob: data,
            nonce: meta2.nonce,
            txDigest: digest,
            blobObjectId: blobObject.id.id,
            deletable,
            encodingType: meta2.metadata.encodingType
          })).certificate
        };
      }
      const meta = metadata2;
      return {
        blobObject,
        metadata: metadata2,
        deletable,
        confirmations: await this.writeEncodedBlobToNodes({
          blobId: metadata2.blobId,
          objectId: blobObject.id.id,
          metadata: meta.metadata,
          sliversByNode: meta.sliversByNode,
          deletable
        })
      };
    };
    const certify = ({
      metadata: metadata2,
      confirmations,
      certificate,
      blobObject,
      deletable
    }) => {
      return {
        blobObject,
        metadata: metadata2,
        transaction: confirmations ? this.certifyBlobTransaction({
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          confirmations,
          deletable
        }) : this.certifyBlobTransaction({
          certificate,
          blobId: metadata2.blobId,
          blobObjectId: blobObject.id.id,
          deletable
        })
      };
    };
    async function getBlob({ blobObject, metadata: metadata2 }) {
      return {
        blobId: metadata2.blobId,
        blobObject
      };
    }
    const stepResults = {};
    function getResults(step, current) {
      if (!stepResults[step]) {
        throw new Error(`${step} must be executed before calling ${current}`);
      }
      return stepResults[step];
    }
    return {
      encode: async () => {
        if (!stepResults.encode) {
          stepResults.encode = await encode();
        }
      },
      register: (options) => {
        stepResults.register = register(getResults("encode", "register"), options);
        return stepResults.register.registerTransaction;
      },
      upload: async (options) => {
        stepResults.upload = await upload(getResults("register", "upload"), options);
      },
      certify: () => {
        stepResults.certify = certify(getResults("upload", "certify"));
        return stepResults.certify.transaction;
      },
      getBlob: async () => {
        return getBlob(getResults("certify", "getBlob"));
      }
    };
  }
};
_storageNodeClient = new WeakMap();
_wasmUrl = new WeakMap();
_packageConfig = new WeakMap();
_suiClient = new WeakMap();
_objectLoader = new WeakMap();
_blobMetadataConcurrencyLimit = new WeakMap();
_readCommittee = new WeakMap();
_cache = new WeakMap();
_uploadRelayConfig = new WeakMap();
_uploadRelayClient = new WeakMap();
_WalrusClient_instances = new WeakSet();
/** The Move type for a WAL coin */
walType_fn = function() {
  return __privateGet(this, _cache).read(["walType"], async () => {
    const stakeWithPool = await __privateGet(this, _suiClient).core.getMoveFunction({
      packageId: await __privateMethod(this, _WalrusClient_instances, getPackageId_fn).call(this),
      moduleName: "staking",
      name: "stake_with_pool"
    });
    const toStake = stakeWithPool.function.parameters[1];
    const toStakeCoin = toStake.body.$kind === "datatype" ? toStake.body.datatype : null;
    const toStakeCoinType = toStakeCoin?.typeParameters[0]?.$kind === "datatype" ? toStakeCoin.typeParameters[0] : null;
    if (toStakeCoinType?.$kind !== "datatype") {
      throw new import_error.WalrusClientError("WAL type not found");
    }
    return (0, import_utils.normalizeStructTag)(toStakeCoinType.datatype.typeName);
  });
};
getPackageId_fn = function() {
  return __privateGet(this, _cache).read(["getPackageId"], async () => {
    const system = await __privateGet(this, _objectLoader).load(__privateGet(this, _packageConfig).systemObjectId);
    return (0, import_utils.parseStructTag)(system.type).address;
  });
};
getWalrusPackageId_fn = function() {
  return __privateGet(this, _cache).read(["getSystemPackageId"], async () => {
    const { package_id } = await this.systemObject();
    return package_id;
  });
};
wasmBindings_fn = function() {
  return __privateGet(this, _cache).read(["wasmBindings"], async () => {
    return (0, import_wasm.getWasmBindings)(__privateGet(this, _wasmUrl));
  });
};
internalReadBlob_fn = async function({ blobId, signal }) {
  const systemState = await this.systemState();
  const numShards = systemState.committee.n_shards;
  const blobMetadata = await this.getBlobMetadata({ blobId, signal });
  const slivers = await this.getSlivers({ blobId, signal });
  const bindings = await __privateMethod(this, _WalrusClient_instances, wasmBindings_fn).call(this);
  const blobBytes = bindings.decodePrimarySlivers(
    blobId,
    numShards,
    blobMetadata.metadata.V1.unencoded_length,
    slivers
  );
  const reconstructedBlobMetadata = bindings.computeMetadata(
    systemState.committee.n_shards,
    blobBytes
  );
  if (reconstructedBlobMetadata.blobId !== blobId) {
    throw new import_error.InconsistentBlobError("The specified blob was encoded incorrectly.");
  }
  return blobBytes;
};
getCertificationEpoch_fn = async function({ blobId, signal }) {
  const stakingState = await this.stakingState();
  const currentEpoch = stakingState.epoch;
  if (stakingState.epoch_state.$kind === "EpochChangeSync") {
    const status = await this.getVerifiedBlobStatus({ blobId, signal });
    if (status.type === "nonexistent" || status.type === "invalid") {
      throw new import_error.BlobNotCertifiedError(`The specified blob ${blobId} is ${status.type}.`);
    }
    if (typeof status.initialCertifiedEpoch !== "number") {
      throw new import_error.BlobNotCertifiedError(`The specified blob ${blobId} is not certified.`);
    }
    if (status.initialCertifiedEpoch > currentEpoch) {
      throw new import_error.BehindCurrentEpochError(
        `The client is at epoch ${currentEpoch} while the specified blob was certified at epoch ${status.initialCertifiedEpoch}.`
      );
    }
    return status.initialCertifiedEpoch;
  }
  return currentEpoch;
};
getReadCommittee_fn = async function(options) {
  if (!__privateGet(this, _readCommittee)) {
    __privateSet(this, _readCommittee, __privateMethod(this, _WalrusClient_instances, forceGetReadCommittee_fn).call(this, options));
  }
  return __privateGet(this, _readCommittee);
};
forceGetReadCommittee_fn = async function({ blobId, signal }) {
  const stakingState = await this.stakingState();
  const isTransitioning = stakingState.epoch_state.$kind === "EpochChangeSync";
  const certificationEpoch = await __privateMethod(this, _WalrusClient_instances, getCertificationEpoch_fn).call(this, { blobId, signal });
  if (isTransitioning && certificationEpoch < stakingState.epoch) {
    return await __privateMethod(this, _WalrusClient_instances, getCommittee_fn).call(this, stakingState.previous_committee);
  }
  return await __privateMethod(this, _WalrusClient_instances, getActiveCommittee_fn).call(this);
};
withWal_fn = function(amount, source, fn) {
  return async (tx) => {
    const walType = await __privateMethod(this, _WalrusClient_instances, walType_fn).call(this);
    const coin = source ? tx.splitCoins(source, [amount])[0] : tx.add(
      (0, import_transactions.coinWithBalance)({
        balance: amount,
        type: walType
      })
    );
    const result = await fn(coin, tx);
    tx.moveCall({
      target: "0x2::coin::destroy_zero",
      typeArguments: [walType],
      arguments: [coin]
    });
    return result;
  };
};
loadTipConfig_fn = function() {
  return __privateGet(this, _cache).read(["upload-relay-tip-config"], async () => {
    if (!__privateGet(this, _uploadRelayConfig)?.sendTip || !__privateGet(this, _uploadRelayClient)) {
      return null;
    }
    if ("kind" in __privateGet(this, _uploadRelayConfig).sendTip) {
      return __privateGet(this, _uploadRelayConfig).sendTip;
    }
    const tipConfig = await __privateGet(this, _uploadRelayClient).tipConfig();
    if (!tipConfig) {
      return null;
    }
    return {
      ...tipConfig,
      max: __privateGet(this, _uploadRelayConfig).sendTip.max
    };
  });
};
getCreatedBlob_fn = async function(digest) {
  const blobType = await this.getBlobType();
  const {
    transaction: { effects }
  } = await __privateGet(this, _suiClient).core.waitForTransaction({
    digest
  });
  const createdObjectIds = effects?.changedObjects.filter((object) => object.idOperation === "Created").map((object) => object.id);
  const createdObjects = await __privateGet(this, _suiClient).core.getObjects({
    objectIds: createdObjectIds
  });
  const suiBlobObject = createdObjects.objects.find(
    (object) => !(object instanceof Error) && object.type === blobType
  );
  if (suiBlobObject instanceof Error || !suiBlobObject) {
    throw new import_error.WalrusClientError(
      `Blob object not found in transaction effects for transaction (${digest})`
    );
  }
  return import_blob.Blob.parse(await suiBlobObject.content);
};
writeBlobAttributesForRef_fn = function({
  attributes,
  existingAttributes,
  blob
}) {
  return async (tx) => {
    const walrusPackageId = await __privateMethod(this, _WalrusClient_instances, getWalrusPackageId_fn).call(this);
    if (!existingAttributes) {
      tx.add(
        (0, import_blob.addMetadata)({
          package: walrusPackageId,
          arguments: {
            self: blob,
            metadata: metadata._new({
              package: walrusPackageId
            })
          }
        })
      );
    }
    Object.keys(attributes).forEach((key) => {
      const value = attributes[key];
      if (value === null) {
        if (existingAttributes && key in existingAttributes) {
          tx.add(
            (0, import_blob.removeMetadataPair)({
              package: walrusPackageId,
              arguments: {
                self: blob,
                key
              }
            })
          );
        }
      } else {
        tx.add(
          (0, import_blob.insertOrUpdateMetadataPair)({
            package: walrusPackageId,
            arguments: {
              self: blob,
              key,
              value
            }
          })
        );
      }
    });
  };
};
executeTransaction_fn = async function(transaction, signer, action) {
  transaction.setSenderIfNotSet(signer.toSuiAddress());
  const { digest, effects } = await signer.signAndExecuteTransaction({
    transaction,
    client: __privateGet(this, _suiClient)
  });
  if (effects?.status.error) {
    throw new import_error.WalrusClientError(`Failed to ${action} (${digest}): ${effects?.status.error}`);
  }
  await __privateGet(this, _suiClient).core.waitForTransaction({
    digest
  });
  return { digest, effects };
};
getCommittee_fn = async function(committee) {
  const stakingPool = await __privateMethod(this, _WalrusClient_instances, stakingPool_fn).call(this, committee);
  const shardIndicesByNodeId = (0, import_utils2.getShardIndicesByNodeId)(committee);
  const byShardIndex = /* @__PURE__ */ new Map();
  const nodes = stakingPool.map(({ node_info }, nodeIndex) => {
    const shardIndices = shardIndicesByNodeId.get(node_info.node_id) ?? [];
    const node = {
      id: node_info.node_id,
      info: node_info,
      networkUrl: `https://${node_info.network_address}`,
      shardIndices,
      nodeIndex
    };
    for (const shardIndex of shardIndices) {
      byShardIndex.set(shardIndex, node);
    }
    return node;
  });
  return {
    byShardIndex,
    nodes
  };
};
getActiveCommittee_fn = function() {
  return __privateGet(this, _cache).read(["getActiveCommittee"], async () => {
    const stakingState = await this.stakingState();
    return __privateMethod(this, _WalrusClient_instances, getCommittee_fn).call(this, stakingState.committee);
  });
};
stakingPool_fn = async function(committee) {
  const nodeIds = committee[0].contents.map((node) => node.key);
  return __privateGet(this, _objectLoader).loadManyOrThrow(nodeIds, import_staking_pool.StakingPool);
};
getNodeByShardIndex_fn = async function(committeeInfo, index) {
  const node = committeeInfo.byShardIndex.get(index);
  if (!node) {
    throw new import_error.WalrusClientError(`Node for shard index ${index} not found`);
  }
  return node;
};
retryOnPossibleEpochChange_fn = function(fn) {
  return (async (...args) => {
    try {
      return await fn.apply(this, args);
    } catch (error) {
      if (error instanceof import_error.RetryableWalrusClientError) {
        this.reset();
        return await fn.apply(this, args);
      }
      throw error;
    }
  });
};
let WalrusClient = _WalrusClient;
//# sourceMappingURL=client.js.map
